{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras.callbacks\n",
    "from keras.layers import Dense, Dropout, Activation, TimeDistributed, Input\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import numpy.ma as ma\n",
    "import catboost\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_types = [\"bc613fb9d5\", \"bd18c260dd\", \"78a254eb1a\", \"60d7fad2cc\", \n",
    "               \"9f449c8a24\", \"44f0b93123\", \"c7863fbab6\", \"287a406e15\", \n",
    "               \"87d86c4ba1\", \"718ac49d0b\", \"1bea63552c\", \"4739c12685\", \n",
    "               \"09dff9a4e6\", \"e1218bb17f\", \"30fe294f41\", \"f3adcadc86\", \n",
    "               \"8fb049c69a\", \"a29c238412\", \"e5e18713a0\", \"bbfc7ae3f7\", \n",
    "               \"9c67e951dd\", \"5d5d31ecb1\", \"81b0435926\", \"8ccd550d04\", \n",
    "               \"416674c7cf\", \"96c40ef2e4\", \"221f9b90a3\", \"4234879f4b\", \n",
    "               \"444d9e80a6\", \"8b6000cce4\", \"d8c799feca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_row(train_part):\n",
    "    train_part = json.loads(train_part)\n",
    "    x_row = []\n",
    "    y_row = []\n",
    "    for data_point in train_part:\n",
    "        x_data_point = [\n",
    "            np.mean(data_point[\"lengths_history\"]),\n",
    "            data_point['user_state'][\"age\"],\n",
    "            data_point['user_state']['height'],\n",
    "            data_point['user_state']['weight'],\n",
    "            data_point['user_state']['period_estimate'],\n",
    "            data_point['user_state']['luteal_estimate'],\n",
    "            data_point['user_state']['cycle_estimate'],\n",
    "            int(data_point['period_passed'])\n",
    "        ]\n",
    "        evts_map = {x['type'] : np.mean(x['value']) for x in data_point['events']}\n",
    "        for evt in event_types:\n",
    "            if evt in evts_map:\n",
    "                x_data_point.append(np.mean(evts_map[evt]))\n",
    "            else:\n",
    "                x_data_point.append(0)\n",
    "        x_data_point = [float('nan') if x is None else x for x in x_data_point]\n",
    "        x_row.append(np.array(x_data_point))\n",
    "        if 'label' in data_point:\n",
    "            lbl = data_point['label']\n",
    "            y_row.append(lbl)\n",
    "    return np.array(x_row), np.array(y_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]/usr/local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "9988it [01:40, 98.95it/s]"
     ]
    }
   ],
   "source": [
    "train_parts = []\n",
    "y_train_parts = []\n",
    "test_parts = []\n",
    "i = 0\n",
    "with open('/Users/vita/Downloads/flo/train_subsample.jsonl', 'r') as train_file, \\\n",
    "        open('/Users/vita/Downloads/flo/test_subsample.jsonl', 'r') as test_file:\n",
    "    for train_part, test_part in zip(tqdm(train_file), test_file):\n",
    "        i = i + 1\n",
    "        if i > 10000:\n",
    "            break\n",
    "            \n",
    "        train_x_row, train_y_row = process_row(train_part)\n",
    "        train_parts.append(train_x_row)\n",
    "        y_train_parts.append(train_y_row)\n",
    "\n",
    "        test_x_row, test_y_row = process_row(test_part)\n",
    "        test_parts.append(process_row(test_part))\n",
    "    y_train_parts = np.array(y_train_parts)\n",
    "    train_parts = np.array(train_parts)\n",
    "    test_parts = np.array(test_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_parts, y_train_parts, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan\n",
    "def fill_nan(data):\n",
    "    return [np.where(np.isnan(x), ma.array(x, mask=np.isnan(x)).mean(axis=0), x) for x in data]\n",
    "\n",
    "X_train = fill_nan(X_train)\n",
    "X_test = fill_nan(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7000, 280, 39), (7000, 280, 1))"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train)\n",
    "y_train = pad_sequences(y_train)\n",
    "\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], 1))\n",
    "\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))\n",
    "    \n",
    "    x = LSTM(10, return_sequences=True)(inputs)\n",
    "    outputs = TimeDistributed(Dense(1))(x)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    \n",
    "    model.compile('adam', 'mean_absolute_error')\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:2: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6300 samples, validate on 700 samples\n",
      "Epoch 1/10\n",
      "6300/6300 [==============================] - 43s - loss: 12.5019 - val_loss: 12.7978\n",
      "Epoch 2/10\n",
      "2688/6300 [===========>..................] - ETA: 24s - loss: 12.2531"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "model.fit(X_train, y_train, batch_size=64, nb_epoch=10, validation_split=0.1, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
