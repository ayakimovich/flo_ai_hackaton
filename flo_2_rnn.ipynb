{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras.callbacks\n",
    "from keras.layers import Dense, Dropout, Activation, TimeDistributed, Input, concatenate\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "from itertools import groupby\n",
    "import numpy.ma as ma\n",
    "import catboost\n",
    "from sklearn import metrics\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "event_types = [\"bc613fb9d5\", \"bd18c260dd\", \"78a254eb1a\", \"60d7fad2cc\", \n",
    "               \"9f449c8a24\", \"44f0b93123\", \"c7863fbab6\", \"287a406e15\", \n",
    "               \"87d86c4ba1\", \"718ac49d0b\", \"1bea63552c\", \"4739c12685\", \n",
    "               \"09dff9a4e6\", \"e1218bb17f\", \"30fe294f41\", \"f3adcadc86\", \n",
    "               \"8fb049c69a\", \"a29c238412\", \"e5e18713a0\", \"bbfc7ae3f7\", \n",
    "               \"9c67e951dd\", \"5d5d31ecb1\", \"81b0435926\", \"8ccd550d04\", \n",
    "               \"416674c7cf\", \"96c40ef2e4\", \"221f9b90a3\", \"4234879f4b\", \n",
    "               \"444d9e80a6\", \"8b6000cce4\", \"d8c799feca\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def process_row(train_part):\n",
    "    train_part = json.loads(train_part)\n",
    "    x_row = []\n",
    "    y_row = []\n",
    "    for data_point in train_part:\n",
    "        x_data_point = [\n",
    "            np.mean(data_point[\"lengths_history\"]),\n",
    "            data_point['user_state'][\"age\"],\n",
    "            data_point['user_state']['height'],\n",
    "            data_point['user_state']['weight'],\n",
    "            data_point['user_state']['period_estimate'],\n",
    "            data_point['user_state']['luteal_estimate'],\n",
    "            data_point['user_state']['cycle_estimate'],\n",
    "            int(data_point['period_passed'])\n",
    "        ]\n",
    "        evts_map = {x['type'] : np.mean(x['value']) for x in data_point['events']}\n",
    "        for evt in event_types:\n",
    "            if evt in evts_map:\n",
    "                x_data_point.append(np.mean(evts_map[evt]))\n",
    "            else:\n",
    "                x_data_point.append(0)\n",
    "        x_data_point = [float('nan') if x is None else x for x in x_data_point]\n",
    "        x_row.append(np.array(x_data_point))\n",
    "        if 'label' in data_point:\n",
    "            lbl = data_point['label']\n",
    "            y_row.append(lbl)\n",
    "    return np.array(x_row), np.array(y_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "0it [00:00, ?it/s]\u001b[A/usr/local/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2909: RuntimeWarning: Mean of empty slice.\n",
      "  out=out, **kwargs)\n",
      "/usr/local/lib/python3.6/site-packages/numpy/core/_methods.py:80: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  ret = ret.dtype.type(ret / rcount)\n",
      "\n",
      "16it [00:00, 155.36it/s]\u001b[A\n",
      "36it [00:00, 175.25it/s]\u001b[A\n",
      "56it [00:00, 183.18it/s]\u001b[A\n",
      "75it [00:00, 184.66it/s]\u001b[A\n",
      "45865it [04:00, 190.98it/s]\n",
      "110it [00:00, 174.75it/s]Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/local/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/usr/local/Cellar/python3/3.6.2/Frameworks/Python.framework/Versions/3.6/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "129593it [10:36, 203.66it/s]\n"
     ]
    }
   ],
   "source": [
    "train_parts = []\n",
    "y_train_parts = []\n",
    "test_parts = []\n",
    "i = 0\n",
    "with open('/Users/vita/Downloads/flo/train_subsample.jsonl', 'r') as train_file, \\\n",
    "        open('/Users/vita/Downloads/flo/test_subsample.jsonl', 'r') as test_file:\n",
    "    for train_part, test_part in zip(tqdm(train_file), test_file):\n",
    "        i = i + 1\n",
    "#         if i > 25000:\n",
    "#             break\n",
    "            \n",
    "        train_x_row, train_y_row = process_row(train_part)\n",
    "        train_parts.append(train_x_row)\n",
    "        y_train_parts.append(train_y_row)\n",
    "\n",
    "#         test_x_row, test_y_row = process_row(test_part)\n",
    "#         test_parts.append(process_row(test_part))\n",
    "    y_train_parts = np.array(y_train_parts)\n",
    "    train_parts = np.array(train_parts)\n",
    "    test_parts = np.array(test_parts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(train_parts, y_train_parts, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill nan\n",
    "def fill_nan(data):\n",
    "    return np.array([np.where(np.isnan(x), ma.array(x, mask=np.isnan(x)).mean(axis=0), x) for x in data])\n",
    "\n",
    "X_train = fill_nan(X_train)\n",
    "X_test = fill_nan(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((90715, 280, 39), (90715, 280, 1))"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = pad_sequences(X_train)\n",
    "y_train = pad_sequences(y_train)\n",
    "y_train = np.reshape(y_train, (y_train.shape[0], y_train.shape[1], 1))\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((38878, 280, 39), (38878, 280, 1))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test = pad_sequences(X_test, maxlen=X_train.shape[1])\n",
    "y_test = pad_sequences(y_test, maxlen=X_train.shape[1])\n",
    "y_test = np.reshape(y_test, (y_test.shape[0], y_test.shape[1], 1))\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/sklearn/utils/validation.py:444: DataConversionWarning: Data with input dtype int32 was converted to float64 by MinMaxScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(90715, 280, 39)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "shp = X_train.shape\n",
    "X_train_scaled = np.reshape(X_train, (-1, shp[2]))\n",
    "X_train_scaled = scaler.fit_transform(X_train_scaled)\n",
    "X_train_scaled = np.reshape(X_train_scaled, shp)\n",
    "X_train_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(38878, 280, 39)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shp = X_test.shape\n",
    "X_test_scaled = np.reshape(X_test, (-1, shp[2]))\n",
    "X_test_scaled = scaler.transform(X_test_scaled)\n",
    "X_test_scaled = np.reshape(X_test_scaled, shp)\n",
    "X_test_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_antrop = np.array(X_train_scaled[:,:,0:7])\n",
    "X_train_evt = np.array(X_train_scaled[:,:,7:])\n",
    "\n",
    "X_test_antrop = np.array(X_test_scaled[:,:,0:7])\n",
    "X_test_evt = np.array(X_test_scaled[:,:,7:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    inputs = Input(shape=(X_train.shape[1], X_train.shape[2]))    \n",
    "    x = LSTM(4, return_sequences=True)(inputs)\n",
    "    outputs = TimeDistributed(Dense(1))(x)\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_model_2():\n",
    "    evts_input = Input(shape=(X_train_evt.shape[1], X_train_evt.shape[2]))    \n",
    "    lstm_out = LSTM(32, return_sequences=True)(evts_input)\n",
    "    lstm_out = Dropout(.5)(lstm_out)\n",
    "    input_2 = Input(shape=(X_train_antrop.shape[1], X_train_antrop.shape[2]))    \n",
    "    x = keras.layers.concatenate([lstm_out, input_2])\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(.25)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(.25)(x)\n",
    "    x = Dense(64, activation='relu')(x)\n",
    "    x = Dropout(.25)(x)\n",
    "    outputs = TimeDistributed(Dense(1))(x)\n",
    "    model = Model(inputs=[evts_input, input_2], outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  if sys.path[0] == '':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 81643 samples, validate on 9072 samples\n",
      "Epoch 1/20\n",
      "81643/81643 [==============================] - 755s - loss: 2.0348 - val_loss: 1.4416\n",
      "Epoch 2/20\n",
      "81643/81643 [==============================] - 749s - loss: 1.9018 - val_loss: 1.3797\n",
      "Epoch 3/20\n",
      "81643/81643 [==============================] - 774s - loss: 1.8235 - val_loss: 1.3788\n",
      "Epoch 4/20\n",
      "81643/81643 [==============================] - 763s - loss: 1.7910 - val_loss: 1.3418\n",
      "Epoch 5/20\n",
      "81643/81643 [==============================] - 752s - loss: 1.7751 - val_loss: 1.3950\n",
      "Epoch 6/20\n",
      "81643/81643 [==============================] - 747s - loss: 1.7628 - val_loss: 1.3628\n",
      "Epoch 7/20\n",
      "81643/81643 [==============================] - 748s - loss: 1.7556 - val_loss: 1.3372\n",
      "Epoch 8/20\n",
      "81643/81643 [==============================] - 756s - loss: 1.7503 - val_loss: 1.3201\n",
      "Epoch 9/20\n",
      "  256/81643 [..............................] - ETA: 787s - loss: 1.6489"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-60-9e87f3069c04>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mmodel_2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_absolute_error'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m model_2.fit([X_train_evt, X_train_antrop], y_train, batch_size=64, nb_epoch=20, \n\u001b[0;32m---> 12\u001b[0;31m             validation_split=0.1, verbose=1, callbacks=[checkpoint])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "checkpoint_dir = \"rnn_2_weights\"\n",
    "filepath = checkpoint_dir + \"/weights-{epoch:02d}-{loss:.2f}-{val_loss:.2f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=0, \n",
    "                             save_best_only=False, mode='auto', save_weights_only=True)\n",
    "if not os.path.exists(checkpoint_dir):\n",
    "    os.mkdir(checkpoint_dir)\n",
    "\n",
    "model_2 = create_model_2()\n",
    "model_2.load_weights('rnn_2_weights/weights-07-1.75-1.32.hdf5')\n",
    "model_2.compile('adam', 'mean_absolute_error')\n",
    "model_2.fit([X_train_evt, X_train_antrop], y_train, batch_size=64, nb_epoch=20, \n",
    "            validation_split=0.1, verbose=1, callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred = model.predict(X_train_scaled[1:2])\n",
    "pred = model_2.predict([X_test_evt, X_test_antrop])\n",
    "# list(zip(pred[0,:,0], y_train[0,:,0]))\n",
    "# list(zip(pred, y_train[0:1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def metric(real, predicted):\n",
    "    assert len(real) == len(predicted)\n",
    "    \n",
    "    users_mae_values = []\n",
    "    for real_labels, predicted_labels in zip(real, predicted):\n",
    "        assert len(real_labels) == len(predicted_labels)\n",
    "        real_labels, predicted_labels = np.array(real_labels), np.array(predicted_labels)\n",
    "        \n",
    "        user_mae = np.mean(np.abs(real_labels - predicted_labels))\n",
    "        users_mae_values.append(user_mae)\n",
    "    \n",
    "    return np.mean(users_mae_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "real = []\n",
    "predicted = []\n",
    "for pair in zip(pred[:,:,0], y_test[:,:,0]):\n",
    "    ind = next((i for i, v in enumerate(pair[1]) if v > 0), -1)\n",
    "    predicted.append(pair[0][ind:])\n",
    "    real.append(pair[1][ind:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RNN = 2.9029015900173714\n"
     ]
    }
   ],
   "source": [
    "print(\"RNN = {}\".format(metric(real, predicted)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 30,  33, 154,  55,   9,   0,   0], dtype=int32),\n",
       " array([25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25, 25,\n",
       "        25, 25, 25, 25, 25, 25, 25, 25, 25, 18, 18, 18, 18, 18, 18, 18, 18,\n",
       "        18, 18, 18, 18, 18, 18, 18, 18, 18, 18, 47, 47, 47, 47, 47, 47, 47,\n",
       "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "        47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47, 47,\n",
       "        47, 47, 47, 47, 47, 47, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27,\n",
       "        27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27, 27], dtype=int32),\n",
       " array([ 24.15056992,  24.23118019,  24.44118118,  24.35130882,\n",
       "         24.42392731,  24.76114655,  24.70909882,  24.72706985,\n",
       "         24.89683151,  25.2110424 ,  25.30344772,  25.25684357,\n",
       "         25.11906624,  24.91732025,  24.81240845,  24.72669792,\n",
       "         24.66095734,  24.6485939 ,  24.64139938,  24.77434921,\n",
       "         24.62004662,  24.69812012,  24.75393677,  24.79447365,\n",
       "         24.8657608 ,  24.82513428,  25.71040726,  25.71256256,\n",
       "         25.85775757,  25.94613266,  26.06824684,  26.24490166,\n",
       "         26.45938683,  26.67898178,  26.88172531,  27.04945755,\n",
       "         27.13142776,  27.16775131,  27.14609528,  27.09082413,\n",
       "         27.01269531,  26.9407959 ,  26.93591881,  26.96014786,\n",
       "         26.52468109,  26.47348976,  26.44507599,  26.30330849,\n",
       "         26.39857864,  26.40717697,  26.47358704,  26.59654999,\n",
       "         26.73401833,  26.68454552,  26.56158638,  26.45105171,\n",
       "         26.32297516,  26.21103477,  26.12934685,  26.11123657,\n",
       "         26.1088047 ,  26.11620712,  26.1352005 ,  26.09046173,\n",
       "         26.13551331,  26.22323418,  26.33374405,  26.56675339,\n",
       "         27.02200317,  27.54985428,  28.24000168,  29.06881142,\n",
       "         30.18562126,  31.23455811,  32.33949661,  33.57252884,\n",
       "         34.64926147,  35.64629745,  36.54351044,  37.42515945,\n",
       "         38.31898117,  39.23108292,  40.15884781,  41.10217667,\n",
       "         41.97284317,  42.69024277,  43.1840744 ,  43.49591827,\n",
       "         43.80897903,  44.29134369,  44.96023178,  32.23708344,\n",
       "         29.58024025,  29.69205475,  30.09978676,  30.16436386,\n",
       "         30.09397507,  30.01960754,  29.94980812,  29.91003036,\n",
       "         29.89899635,  29.93297386,  29.96962166,  30.00192642,\n",
       "         30.02596474,  30.04048157,  30.05619621,  30.06215096,\n",
       "         30.05811882,  30.04426193,  30.05211258,  30.14828682,\n",
       "         30.24412537,  30.34606171,  30.43771744,  30.52677536,\n",
       "         30.49944687,  30.6100235 ], dtype=float32))"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i=5\n",
    "X_test[i, -1, 0:7], real[i], predicted[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 31,  19, 165,   0,   5,   0,  28], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test[0,-1,:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler.inverse_transform(X_train_antrop[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
